{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "violent-helen",
   "metadata": {},
   "source": [
    "# Tensor Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legitimate-relevance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7018, 0.9645, 0.8287, 0.3934, 0.8088, 0.4162, 0.0602, 0.7012, 0.8931,\n",
      "         0.0113, 0.7554, 0.0822, 0.9344, 0.4410, 0.3756, 0.1685, 0.0469, 0.0399,\n",
      "         0.7201, 0.7876, 0.6903, 0.7990, 0.6754, 0.8061, 0.2370],\n",
      "        [0.1229, 0.9515, 0.6432, 0.2256, 0.8148, 0.6619, 0.0295, 0.9752, 0.4956,\n",
      "         0.3947, 0.8354, 0.2532, 0.1234, 0.7376, 0.1052, 0.2425, 0.8024, 0.3134,\n",
      "         0.7071, 0.9081, 0.2126, 0.5742, 0.0128, 0.6751, 0.0495],\n",
      "        [0.8946, 0.7254, 0.6463, 0.2092, 0.5480, 0.6857, 0.0052, 0.4459, 0.2176,\n",
      "         0.6828, 0.3498, 0.3557, 0.4613, 0.1838, 0.4753, 0.8213, 0.1969, 0.6311,\n",
      "         0.4128, 0.3717, 0.9108, 0.4270, 0.3075, 0.9937, 0.0631],\n",
      "        [0.0484, 0.6066, 0.5425, 0.1122, 0.8362, 0.5178, 0.3101, 0.2113, 0.3984,\n",
      "         0.4771, 0.0149, 0.2401, 0.3673, 0.9467, 0.8321, 0.5261, 0.4509, 0.9745,\n",
      "         0.9612, 0.2386, 0.4277, 0.3290, 0.1398, 0.6732, 0.1601],\n",
      "        [0.8995, 0.4233, 0.8007, 0.8225, 0.1371, 0.9864, 0.1094, 0.7093, 0.5073,\n",
      "         0.1469, 0.2258, 0.3003, 0.4037, 0.3026, 0.8772, 0.5135, 0.9387, 0.8914,\n",
      "         0.5903, 0.1395, 0.8252, 0.2431, 0.6661, 0.9433, 0.2834],\n",
      "        [0.0065, 0.9153, 0.6372, 0.7933, 0.6351, 0.8882, 0.8375, 0.2193, 0.9995,\n",
      "         0.6343, 0.9240, 0.3294, 0.5229, 0.2957, 0.2037, 0.7478, 0.4335, 0.2544,\n",
      "         0.5278, 0.7804, 0.7003, 0.8682, 0.0877, 0.4670, 0.6490],\n",
      "        [0.1675, 0.2734, 0.6669, 0.5545, 0.3758, 0.2710, 0.4030, 0.3786, 0.7397,\n",
      "         0.4214, 0.1544, 0.4050, 0.2092, 0.5418, 0.0307, 0.1061, 0.7266, 0.9834,\n",
      "         0.8257, 0.8785, 0.5562, 0.5641, 0.5221, 0.0154, 0.1549],\n",
      "        [0.5648, 0.9344, 0.1357, 0.8800, 0.7560, 0.5217, 0.3563, 0.1527, 0.0108,\n",
      "         0.8820, 0.2330, 0.4768, 0.7421, 0.2301, 0.0614, 0.1144, 0.0672, 0.2194,\n",
      "         0.8874, 0.9460, 0.0668, 0.8031, 0.9854, 0.7241, 0.0871],\n",
      "        [0.3596, 0.6595, 0.7710, 0.0700, 0.2322, 0.9538, 0.7873, 0.2212, 0.4828,\n",
      "         0.0153, 0.9821, 0.0340, 0.3591, 0.4691, 0.6517, 0.8498, 0.0155, 0.3487,\n",
      "         0.9668, 0.8145, 0.9641, 0.3990, 0.3057, 0.3352, 0.7296],\n",
      "        [0.2674, 0.3371, 0.3573, 0.4665, 0.6111, 0.8718, 0.8916, 0.3015, 0.7015,\n",
      "         0.3759, 0.0455, 0.6287, 0.6822, 0.8613, 0.6046, 0.2591, 0.6058, 0.2479,\n",
      "         0.6606, 0.5596, 0.7953, 0.4746, 0.6934, 0.8243, 0.7286]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "batch_size = 10\n",
    "features = 25\n",
    "x = torch.rand((batch_size,features))\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precious-investor",
   "metadata": {},
   "source": [
    "# Finding the features of first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "blank-adjustment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7018, 0.9645, 0.8287, 0.3934, 0.8088, 0.4162, 0.0602, 0.7012, 0.8931,\n",
      "        0.0113, 0.7554, 0.0822, 0.9344, 0.4410, 0.3756, 0.1685, 0.0469, 0.0399,\n",
      "        0.7201, 0.7876, 0.6903, 0.7990, 0.6754, 0.8061, 0.2370])\n",
      "torch.Size([25])\n"
     ]
    }
   ],
   "source": [
    "print(x[0])\n",
    "print(x[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-corporation",
   "metadata": {},
   "source": [
    "# Getting first features from every batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "general-friendly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7018, 0.1229, 0.8946, 0.0484, 0.8995, 0.0065, 0.1675, 0.5648, 0.3596,\n",
      "        0.2674])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "print(x[:,0])\n",
    "print(x[:,0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lined-somalia",
   "metadata": {},
   "source": [
    "# Getting first 10 features from the third batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alleged-mount",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8946, 0.7254, 0.6463, 0.2092, 0.5480, 0.6857, 0.0052, 0.4459, 0.2176,\n",
      "        0.6828])\n"
     ]
    }
   ],
   "source": [
    "print(x[2,0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-charm",
   "metadata": {},
   "source": [
    "# Fancy Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stretch-pressing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 5, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "indices = [2,5,8]\n",
    "print(x[indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-survey",
   "metadata": {},
   "source": [
    "# More advanced indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "obvious-proposition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 9])\n",
      "tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "print(x[(x <2) | (x >8)])\n",
    "print(x[x.remainder(2) == 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composed-portugal",
   "metadata": {},
   "source": [
    "# Useful operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "monetary-venue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  2,  4,  6,  8, 10,  6,  7,  8,  9])\n",
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "print (torch.where(x>5, x, x*2))\n",
    "#printing unique values from the list\n",
    "print(torch.tensor([0,0,1,1,2,2,3,4]).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fiscal-gallery",
   "metadata": {},
   "source": [
    "# Finding the dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.ndimension)\n",
    "print9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
